{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"A walkthough of submitting a simple model in python\"\n",
        "description: |\n",
        "  Here we show the steps for submitting a simple model in `python`\n",
        "categories:\n",
        "  - dataset\n",
        "  - guide\n",
        "author: \n",
        "  - \"Gert Stulp\"\n",
        "  - \"Lisa Sivak\"\n",
        "date: '2024-03-26'\n",
        "toc: true\n",
        "image: ../../images/python_submission.jpg\n",
        "image-alt: LISS logo. \n",
        "language: \n",
        "    section-title-footnotes: References\n",
        "---"
      ],
      "id": "7d29872d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we describe how to prepare and make a submission for Python users.  \n",
        "\n",
        "Disclaimer: the data preprocessing and the model that we will train here are very basic. You should not use it as an example of how to properly train a model (e.g. imputing missing values with a mean or mode is often a bad idea). The sole purpose of this script is to make the submission process more clear.   \n",
        "\n",
        "In this example we assume that you are using [GitHub Desktop](https://docs.github.com/en/desktop), which is a very convenient tool for updating your github repository. [Here](https://github.com/eyra/fertility-prediction-challenge/wiki) you can find useful links how to use GitHub Desktop for cloning your repository and for update the files in it.  \n",
        "\n",
        "We also assume that you did all the prerequisite steps described   [here](https://github.com/eyra/fertility-prediction-challenge?tab=readme-ov-file#prerequisites){target=\"_blank\"}.  \n",
        "\n",
        "Let's imagine that you want to add one predictor to the model that is already in the repository: respondent's gender (variable name \"gender_bg\", as you found using the codebooks). To produce this model you should use the template functions that are already in the repository:  \"clean_df\" for preprocessing the data from the \"submission.py\", \"train_save_model\" from \"training.py\" and \"predict_outcomes\" from \"submission.py\".   \n",
        "\n",
        "Overall steps: preprocessing the data —> training and saving the model —> testing on the fake data —> editing \"submission.py\" and \"training.py\" accordingly —> submitting.   \n",
        "\n",
        "1. Create a new script in the environment for python that you normally use, save the file in the folder with your cloned repository. Import necessary packages and read training data and outcome. !IMPORTANT: do not add the data to the folder on your computer with the files from your repository. If you put the data in this folder and then upload all the changes online, the data will be made public in your online github repository. \n",
        "\n",
        "```{{python}}\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "# loading features\n",
        "train = pd.read_csv(\"path to the data which is NOT your cloned repository\\\\PreFer_train_data.csv\", low_memory = False) # explain low_memory = False\n",
        "# loading the outcome\n",
        "outcome = pd.read_csv(\"path to the data which is NOT your cloned repository\\\\PreFer_train_outcome.csv\", low_memory = False) \n",
        "```\n",
        "\n",
        "2. Copy paste the `clean_df` function from the \"submission.py\" into this script. Edit the `clean_df` function - add the new variable: \n",
        "\n",
        "```{{python}}\n",
        "def clean_df(df, background_df=None):\n",
        "    \"\"\"\n",
        "    Preprocess the input dataframe to feed the model.\n",
        "    # If no cleaning is done (e.g. if all the cleaning is done in a pipeline) leave only the \"return df\" command\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The input dataframe containing the raw data (e.g., from PreFer_train_data.csv or PreFer_fake_data.csv).\n",
        "    background (pd.DataFrame): Optional input dataframe containing background data (e.g., from PreFer_train_background_data.csv or PreFer_fake_background_data.csv).\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: The cleaned dataframe with only the necessary columns and processed variables.\n",
        "    \"\"\"\n",
        "\n",
        "    ## This script contains a bare minimum working example\n",
        "    # Create new variable with age\n",
        "    df[\"age\"] = 2024 - df[\"birthyear_bg\"]\n",
        "\n",
        "    # Imputing missing values in age with the mean\n",
        "    df[\"age\"] = df[\"age\"].fillna(df[\"age\"].mean())\n",
        "\n",
        "    # Selecting variables for modelling\n",
        "    keepcols = [\n",
        "        \"nomem_encr\",  # ID variable required for predictions,\n",
        "        \"age\"         # newly created variable\n",
        "        ,\"gender_bg\"  # <--------ADDED VARIABLE\n",
        "    ] \n",
        "\n",
        "    # Keeping data with variables selected\n",
        "    df = df[keepcols]\n",
        "\n",
        "    return df\n",
        "```\n",
        "\n",
        "3. Copy paste the `train_save_model` function from the \"training.py\" and edit it - add the new variable:\n",
        "\n",
        "```{{python}}\n",
        "def train_save_model(cleaned_df, outcome_df):\n",
        "    \"\"\"\n",
        "    Trains a model using the cleaned dataframe and saves the model to a file.\n",
        "\n",
        "    Parameters:\n",
        "    cleaned_df (pd.DataFrame): The cleaned data from clean_df function to be used for training the model.\n",
        "    outcome_df (pd.DataFrame): The data with the outcome variable (e.g., from PreFer_train_outcome.csv or PreFer_fake_outcome.csv).\n",
        "    \"\"\"\n",
        "    \n",
        "    ## This script contains a bare minimum working example\n",
        "    #random.seed(1) # not useful here because logistic regression deterministic\n",
        "    \n",
        "    # Combine cleaned_df and outcome_df\n",
        "    model_df = pd.merge(cleaned_df, outcome_df, on=\"nomem_encr\")\n",
        "\n",
        "    # Filter cases for whom the outcome is not available\n",
        "    model_df = model_df[~model_df['new_child'].isna()]  \n",
        "    \n",
        "    # Logistic regression model\n",
        "    model = LogisticRegression()\n",
        "\n",
        "    # Fit the model\n",
        "    model.fit(model_df[['age', 'gender_bg']], model_df['new_child']) # <------- ADDED VARIABLE\n",
        "\n",
        "    # Save the model\n",
        "    joblib.dump(model, \"model.joblib\")\n",
        "\n",
        "```\n",
        "\n",
        "4. Preprocess the data using your updated `clean_df` function, and then train the model. Now the model is saved in the same folder. "
      ],
      "id": "d282b5db"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# preprocessing the data\n",
        "train_cleaned = clean_df(train)\n",
        "\n",
        "# training and saving the model\n",
        "train_save_model(train_cleaned, outcome)"
      ],
      "id": "d4df0cf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Test the preprocessing function and model on fake data to see if they will run on the holdout set. If your method does not run on the \"fake data\", it will not run on the holdout data. [If you \"push\" your method to Github this test will also be automatically run].  \n",
        "\n",
        "To do this test you can copy paste the function `predict_outcomes` from the \"submission.py\". Load the fake data (it is already in your local repository folder) and apply the `predict_outcomes`.\n",
        "\n",
        "```{{python}}\n",
        "# load the data\n",
        "fake = pd.read_csv(\"PreFer_fake_data.csv\") \n",
        "\n",
        "def predict_outcomes(df, background_df=None, model_path=\"model.joblib\"):\n",
        "    \"\"\"Generate predictions using the saved model and the input dataframe.\n",
        "\n",
        "    The predict_outcomes function accepts a Pandas DataFrame as an argument\n",
        "    and returns a new DataFrame with two columns: nomem_encr and\n",
        "    prediction. The nomem_encr column in the new DataFrame replicates the\n",
        "    corresponding column from the input DataFrame. The prediction\n",
        "    column contains predictions for each corresponding nomem_encr. Each\n",
        "    prediction is represented as a binary value: '0' indicates that the\n",
        "    individual did not have a child during 2021-2023, while '1' implies that\n",
        "    they did.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The input dataframe for which predictions are to be made.\n",
        "    background_df (pd.DataFrame): The background dataframe for which predictions are to be made.\n",
        "    model_path (str): The path to the saved model file (which is the output of training.py).\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A dataframe containing the identifiers and their corresponding predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    ## This script contains a bare minimum working example\n",
        "    if \"nomem_encr\" not in df.columns:\n",
        "        print(\"The identifier variable 'nomem_encr' should be in the dataset\")\n",
        "\n",
        "    # Load the model\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "    # Preprocess the fake / holdout data\n",
        "    df = clean_df(df, background_df)\n",
        "\n",
        "    # Exclude the variable nomem_encr if this variable is NOT in your model\n",
        "    vars_without_id = df.columns[df.columns != 'nomem_encr']\n",
        "\n",
        "    # Generate predictions from model, should be 0 (no child) or 1 (had child)\n",
        "    predictions = model.predict(df[vars_without_id])\n",
        "\n",
        "    # Output file should be DataFrame with two columns, nomem_encr and predictions\n",
        "    df_predict = pd.DataFrame(\n",
        "        {\"nomem_encr\": df[\"nomem_encr\"], \"prediction\": predictions}\n",
        "    )\n",
        "\n",
        "    # Return only dataset with predictions and identifier\n",
        "    return df_predict\n",
        "\n",
        "# apply the function to the fake data\n",
        "predict_outcomes(fake)\n",
        "```\n",
        "\n",
        "If you see the predictions, not errors, everything worked.\n",
        "![](/images/fake_data_predictions.png)\n",
        "You can now prepare the files for submission, that will be applied to the holdout set.  \n",
        "\n",
        "6. \"submission.py\": edit this script by copypasting your clean_df function there. This code will be applied to the holdout data. You don't need to adapt the `predict_outcomes` function in submission.py because the outputs of your model are predicted classes already (i.e., 0s and 1s), and not, for example, probabilities.   \n",
        "\n",
        "7. prediction model: make sure that your model is saved in the same folder as submission.py under the name model.joblib  \n",
        "\n",
        "8. \"environment.yml\": you don't have to edit this file now, because you used only the packages that are already there.  \n",
        "\n",
        "9. \"training.py\": copy paste your updated `train_save_model` function and the packages needed for this function to run to this script.  \n",
        "\n",
        "\n",
        "Now you need to update your online github repository:\n",
        "\n",
        "10. Go to GitHub Desktop and save changes (i.e. commit).\n",
        "\n",
        "![](/images/commit.png)\n",
        "\n",
        "\n",
        "11. Push the changes (\"Push origin\") (i.e. update your online repository) - press \"Push origin\" on the upper right.  \n",
        "\n",
        "12. Now go to the Action page in you online github repository. After a few minutes you'll see if your submission passed the automatic checks.  \n",
        "\n",
        "13. Submit your method as explained [here](https://github.com/eyra/fertility-prediction-challenge/tree/master#submit-your-method){target=\"_blank\"}. \n"
      ],
      "id": "b2737472"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}