{
  "hash": "fe9c73a15568974a428885523965fe73",
  "result": {
    "markdown": "---\ntitle: \"A walkthough of submitting a simple model in R\"\ndescription: |\n  Here we show the steps for submitting a simple model in `R`  \ncategories:\n  - submission\n  - guide\nauthor: \n  - \"Lisa Sivak\"\n  - \"Gert Stulp\"\ndate: '2024-03-25'\ntoc: true\nimage: ../../images/submission_basic_R.png\nimage-alt: LISS logo. \nlanguage: \n    section-title-footnotes: References\n---\n\n\nHere we describe how to prepare and make a submission in R. The sole purpose of this script is to make the submission process more clear, not to present a model that is any good.       \n\n***\n\nIn this example, we assume that you did all the prerequisite steps described [here](https://github.com/eyra/fertility-prediction-challenge?tab=readme-ov-file#prerequisites){target=\"_blank\"}. You have forked and cloned (e.g. downloaded) the GitHub repository, and now have a folder with all the files from this repository on your computer. We will call this folder your \"local repository\".    \n\nLet's imagine that you want to add one predictor to the basic model that is already in the repository: respondents' gender (variable name `gender_bg`, as you found using the [codebooks](2024-03-21-prefer-codebooks.qmd)). To produce this model you should use the template functions that are already in the repository: `clean_df` for preprocessing the data from the \"submission.R\" script, `train_save_model` from the \"training.R\" script, and `predict_outcomes` from the \"submission.R\" script (to test your model and preprocessing).   \n\n__Overall steps__: reading in the data —> preprocessing the data —> training and saving the model —> testing on the fake data —> editing/saving \"submission.R\", \"training.R\", \"packages.R\" accordingly —> adding a short description of the method to `description.md` —> pushing your materials to the online Github repository -> submitting.   \n\n## Reading-in data    \n\n1. [Read-in](2024-03-22-read-data.qmd) the training data and outcome. __IMPORTANT__: it is strongly advised to save the PreFer datafiles in a *different* folder than your local repository. The reason is that these datasets **cannot** be made public, and when you save the datasets in your local repository you may accidentally upload the datasets to your online repository when you \"push\" your latest changes. This would constitute a serious data breach.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading data (predictors)\nlibrary(data.table) # requires install.packages(\"data.table\") first\ntrain <- data.table::fread(\"path to the data which is NOT in your local repository/PreFer_train_data.csv\",\n                           keepLeadingZeros = TRUE, # if FALSE adds zeroes to some dates\n                           data.table = FALSE)\n# base R's read.csv is also possible but is ssssllloooowww\n\n# loading the outcome\noutcome <- data.table::fread(\"path to the data which is NOT in your local repository/PreFer_train_outcome.csv\",\n                             data.table = FALSE) \n```\n:::\n\n\n## Preprocessing and training   \n\n2. Find your folder with the PreFer materials, and open the `submission.R` script. Edit the `clean_df` function: add the new variable: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_df <- function(df, background_df = NULL) {\n    # Process the input data to feed the model\n  \n    # calculate age   \n    df$age <- 2024 - df$birthyear_bg\n\n    # Selecting variables for modelling\n\n    keepcols = c('nomem_encr', # ID variable required for predictions,\n                 'age', \n                 'gender_bg')  # <-------- ADDED VARIABLE 'gender_bg'\n  \n    # Keeping data with variables selected\n    df <- df[ , keepcols ]\n    \n    # turning gender into factor\n    df$gender_bg<- as.factor(df$gender_bg) # <-------- ADDED THIS\n\n    return(df)\n}\n```\n:::\n\n\nNow your `clean_df` function is done. Make sure to save it and load it into your R environment.\n\n3. Edit the `train_save_model` function from the \"training.R\": add the new variable:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_save_model <- function(cleaned_df, outcome_df) {\n  # Trains a model using the cleaned dataframe and saves the model to a file.\n\n  # Parameters:\n  # cleaned_df (dataframe): The cleaned data from clean_df function to be used for training the model.\n  # outcome_df (dataframe): The data with the outcome variable (e.g., from PreFer_train_outcome.csv or PreFer_fake_outcome.csv).\n\n  ## This script contains a bare minimum working example\n  set.seed(1) # not useful here because logistic regression deterministic\n  \n  # Combine cleaned_df and outcome_df\n  model_df <- merge(cleaned_df, outcome_df, by = \"nomem_encr\")\n  \n  # Logistic regression model\n  model <- glm(new_child ~ age + gender_bg, family = \"binomial\", data = model_df) # <-------- ADDED VARIABLE 'gender_bg'\n  \n  # Save the model\n  saveRDS(model, \"model.rds\")\n}\n```\n:::\n\n\nNow your `train_save_model` function is done. Make sure to save it and load it into your R environment. \n\n4. Preprocess the data using your updated `clean_df` function, and then train the model via `train_save_model`. If you are working in a R Markdown or R Notebook document in RStudio, or when you have opened an Rproject (recommended!), the model (`model.rds`) will be saved in the same folder as your scripts -- in your local repository. If you are working via an R script, you will probably need to manually set the local repository as the working directory.   \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# setwd(\"path to your local repository\") # <---- provide the path here\n\n# preprocessing the data\ntrain_cleaned <- clean_df(train)\n\n# training and saving the model\ntrain_save_model(train_cleaned, outcome)\n```\n:::\n\n\nYour model is trained, and saved in `model.rds`. \n\n## Testing on fake data\n\n5. Test the preprocessing function and model on fake data to see if they will run on the holdout set. If your method does not run on the \"fake data\", it will not run on the holdout data. [If you \"push\" your method to Github this test will also be automatically run].  \n\nTo do this test you can edit the function `predict_outcomes` from the \"submission.R\". Load the fake data (it is already in your local repository) and apply the `predict_outcomes`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the fake data\nfake <- data.table::fread(\"PreFer_fake_data.csv\",\n                          keepLeadingZeros = TRUE, # if FALSE adds zeroes to some dates\n                          data.table = FALSE)\n\npredict_outcomes <- function(df, background_df = NULL, model_path = \"./model.rds\"){\n  # Generate predictions using the saved model and the input dataframe.\n    \n  # The predict_outcomes function accepts a dataframe as an argument\n  # and returns a new dataframe with two columns: nomem_encr and\n  # prediction. The nomem_encr column in the new dataframe replicates the\n  # corresponding column from the input dataframe The prediction\n  # column contains predictions for each corresponding nomem_encr. Each\n  # prediction is represented as a binary value: '0' indicates that the\n  # individual did not have a child during 2021-2023, while '1' implies that\n  # they did.\n  \n  # Parameters:\n  # df (dataframe): The data dataframe for which predictions are to be made.\n  # background_df (dataframe): The background data dataframe for which predictions are to be made.\n  # model_path (str): The path to the saved model file (which is the output of training.R).\n\n  # Returns:\n  # dataframe: A dataframe containing the identifiers and their corresponding predictions.\n  \n  ## This script contains a bare minimum working example\n  if( !(\"nomem_encr\" %in% colnames(df)) ) {\n    warning(\"The identifier variable 'nomem_encr' should be in the dataset\")\n  }\n\n  # Load the model\n  model <- readRDS(model_path)\n    \n  # Preprocess the fake / holdout data\n  df <- clean_df(df, background_df)\n\n  # Exclude the variable nomem_encr if this variable is NOT in your model\n  vars_without_id <- colnames(df)[colnames(df) != \"nomem_encr\"]\n  \n  # Generate predictions from model\n  predictions <- predict(model, \n                         subset(df, select = vars_without_id), \n                         type = \"response\") \n  \n  # Create predictions that should be 0s and 1s rather than, e.g., probabilities\n  predictions <- ifelse(predictions > 0.5, 1, 0)  \n  \n  # Output file should be data.frame with two columns, nomem_encr and predictions\n  df_predict <- data.frame(\"nomem_encr\" = df[ , \"nomem_encr\" ], \"prediction\" = predictions)\n  # Force columnnames (overrides names that may be given by `predict`)\n  names(df_predict) <- c(\"nomem_encr\", \"prediction\") \n  \n  # Return only dataset with predictions and identifier\n  return( df_predict )\n}\n\n\n# apply the function to the fake data\npredict_outcomes(fake)\n```\n:::\n\n\nIf you get a data.frame including predictions, your test on the fake data has passed!  \n![](../..//images/fake_data_predictions.png)\n\n\n## Edit/save files for submission\n\nYou can now prepare the files for submission, that will be applied to the holdout set:      \n\n6. Edit/Save the `clean_df` function in your \"submission.R\". This code will be applied to the holdout data. You don't need to adapt the `predict_outcomes` function in \"submission.R\" because the outputs of your model are predicted classes already (i.e., 0s and 1s).   \n\n7. prediction model: make sure that your model is saved in the same folder as submission.R under the name `model.rds`.   \n8. \"packages.R\": you don't have to edit this file now, because you didn't used any packages.  \n\n9. Edit/Save the `train_save_model` function in the \"training.R\" scripts.  \n\n## Adding a description\n\n10. Add a brief description of your method to the file `description.md` (e.g. \"binary logistic regression with two variables - age and gender - selected manually\")  \n\n## Update online GitHub repository\n\nNow you need to update your online GitHub repository. You can do it in several ways. Here we assume that you used GitHub Desktop for cloning the repository and will also use it to commit (i.e. capture the state of the local repository at that point in time) and push the changes (e.g. change the online repository):\n\n10. Go to GitHub Desktop and press \"Commit to master\". You need to add some description (e.g. \"add gender\").  \n\n![](../../images/commit.png)\n\n\n11. Push the changes (\"Push origin\") (i.e. update your online repository) - press \"Push origin\" on the upper right.  \n\n12. Now go to the \"Actions\" tab in you online github repository. After a few minutes you'll see if your submission passed the automatic checks.  \n\n## Submit your method \n\n13. Submit your method as explained [here](https://github.com/eyra/fertility-prediction-challenge/tree/master#submit-your-method){target=\"_blank\"}. \n\n\n__IMPORTANT__: always save the code that you used to produce the model via the `train_save_model` function. Eventhough this function will not be run om the holdout data, we [the PreFer organisers] will use it to ensure reproducibility and verify whether the predictions you submitted are the same as the predictions that arise from your code stored in `train_save_model`.  \n\n\n<font size=\"-1\">Photo by <a href=\"https://unsplash.com/@ffstop?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Fotis Fotopoulos</a> on <a href=\"https://unsplash.com/photos/black-computer-keyboard-DuHKoV44prg?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a></font> | <font size=\"-1\">Photo by <a href=\"https://unsplash.com/@kelli_mcclintock?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Kelli McClintock</a> on <a href=\"https://unsplash.com/photos/white-box-on-white-table-GopRYASfsOc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a></font>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}