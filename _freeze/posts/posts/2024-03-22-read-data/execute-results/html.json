{
  "hash": "9c1fab16e82ecd59e2afab023c7e5775",
  "result": {
    "markdown": "---\ntitle: \"Reading in data [LISS]\"\ndescription: |\n  Here is some useful information on reading in / load PreFer data.   \ncategories:\n  - dataset\n  - guide\nauthor: \n  - \"Gert Stulp\"\n  - \"Lisa Sivak\"\ndate: '2024-03-22'\ntoc: true\nimage: ../../images/liss_pick.png\nimage-alt: LISS logo. \nlanguage: \n    section-title-footnotes: References\n---\n\n\n\nHere we describe ways of reading-in the data for both Python and R.  \n\nNote that different packages may lead to partly different datasets (for example, with columns of different types), because of the way different packages treat things like missing values, empty strings, and dates. \n\n\n# Reading in the data\n\nThe most important dataset of the PreFer data challenge is the `PreFer_train_data.csv` dataset ([click here](2024-03-20-prefer-datasets.qmd) for information on the datasets that are available). It contains data on all LISS respondents who were between the ages of 18 and 45 in 2020 (i.e., had birthyears between 1975 and 2002). We will see how we can read-in this data with the help of R or Python. \n\n\n## R\n\nThere are several ways in which one could read data into R, but some of them are more successful and quicker than others (TL;DR: use `data.table::fread`).   \n\n### read.csv\n`read.csv` works, requires no additional packages, but is *very* slow. \n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read.csv(\"path/to/folder/PreFer_train_data.csv\", row.names = FALSE) # this works but is very slow\n```\n:::\n\n\n### read_csv\n`readr::read_csv` from the package `readr` in principle works, but gets many of the column types wrong with default settings (because, by default, it only bases column types on the first 1000 values present in the variable). Do not run this code `data <- readr::read_csv(\"PreFer_train_data.csv\")`, but use the following code which explicitly tells `read_csv` that it must make use of the entire column (i.e., all cases) to make a guess of the column type:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr) # requires install.packages(\"readr\") first\ndata <- readr::read_csv(\"path/to/folder/PreFer_train_data.csv\", guess_max = 6418) # this works but is slow\n# 6418 is the number of rows in the data\n```\n:::\n\n\n### fread\n`data.table::fread` from the package `data.table` works like a charm and is very fast. Some additional arguments are useful to avoid default behaviour. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table) # requires install.packages(\"data.table\") first\ndata <- data.table::fread(\"path/to/folder/PreFer_train_data.csv\", \n                          keepLeadingZeros = TRUE, # if FALSE adds zeroes to some dates\n                          data.table = FALSE) # returns a data.frame object rather than data.table \n```\n:::\n\n\n\n## Python\n\n### read_csv from pandas\n`read_csv` from `pandas` works, but is slow. Specifying `low_memory=False` is needed. If `low_memory=False`, then whole columns are read in first, and then the proper data types in the columns are determined. If `low_memory=True` (default), then `pandas` reads in the data in chunks of rows, then appends them together. This results in lower memory use while parsing, but incorrect (mixed) type of data in a column, when for example there are many missing values in a column (which are floating point numbers in python) but all other values are integers.  \n```{{python}}\nimport pandas as pd # requires installing pandas first\ntrain = pd.read_csv(\"path to the data which is NOT in your local repository\\\\PreFer_train_data.csv\", low_memory = False) # this works but is slow\n```\n\n\n### read_csv from polars \n`read_csv` from the `polars` package takes less time. `Polars` is a `pandas` alternative designed to process data faster. If you want to work with a pandas dataframe, use `to_pandas()` to convert. For that, `pyarrow` package also needs to be installed.  \n\n`infer_schema_length=6418` is needed to increase the number of lines used for determining column types; 6418 is the number of rows in the data.  \n```{{python}}\nimport polars as pl     # requires installing polars first\nimport pyarrow          # requires installing pyarrow first\ntrain = pd.read_csv(\"path to the data which is NOT in your local repository\\\\PreFer_train_data.csv\", infer_schema_length=6418).to_pandas() \n```",
    "supporting": [
      "2024-03-22-read-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}