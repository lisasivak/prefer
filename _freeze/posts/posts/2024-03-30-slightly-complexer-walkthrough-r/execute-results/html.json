{
  "hash": "18e101fbb7cab717fc0c04f1b9ad53cd",
  "result": {
    "markdown": "---\ntitle: \"A walkthough of submitting a simple model in R\"\ndescription: |\n  Here we show the steps for submitting a simple model in `R`  \ncategories:\n  - submission\n  - guide\n  - R\nauthor: \n  - \"Gert Stulp\"\n  - \"Lisa Sivak\"\ndate: '2024-03-30'\ntoc: true\nimage: ../../images/submission_basic_R.png\nimage-alt: LISS logo. \nlanguage: \n    section-title-footnotes: References\n---\n\n\nHere we describe how to prepare and make a slighty more complex submission in R than [this one](2024-03-25-simple-walkthrough-r.qmd){target=\"_blank\"}. The sole purpose of this script is to make the submission process more clear by showing some of the errors that you might bump into, not to present a model that is any good.       \n\n***\n\nOur aim is to run a penalized regression via the package `glmnet`. We're only doing a penalized regression with three variables, `birthyear_bg`, `gender_bg`, and `oplmet_2020`. \n\n# Working on submission.R \nWe are going to use the packages `dplyr`, `tidyr`, and `glmnet` so we're going to put these at the top of `submission.R`. Then we'll start by selecting the variables, processing these variables, and then turn the dataset into a matrix, needed for the function `glmnet`. We'll use the function `model.matrix` to conveniently turn our factors into dummies. \n\n*First part of submission.R:*\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(glmnet)\n\nclean_df <- function(df, background_df = NULL){\n  \n  ## Selecting variables\n  keepcols = c('nomem_encr', # ID variable required for predictions,\n               'birthyear_bg', # birthyear of respondents\n               'gender_bg', # gender of respondents, factor\n               'oplmet_2020') # highest educational level in 2020\n  \n  ## Keeping data with variables selected\n  df <- df |> select(all_of(keepcols))\n  \n  df <- df |>\n    # standardise continuous variable, create factor for categorical variables\n    # needed for glmnet\n    mutate(\n      birthyear_bg = as.numeric(scale(birthyear_bg)), # z-scores, as.numeric to remove attributes\n      gender_bg = factor(gender_bg),\n      oplmet_2020 = factor(oplmet_2020)\n    )\n  \n  # turn factors into dummy variables, required for glmnet\n  df <- model.matrix(~ ., df)\n  \n  return(df)\n  \n}\n```\n:::\n\n\n## Testing clean_df\nLet's test if our `clean_df` function works. Let's read in the `PreFer_train_data.csv` (which you hopefully have in a different folder than your local repository; see step 1 [here](2024-03-25-simple-walkthrough-r.qmd) {target=\"_blank\"}). Let's also read-in the outcome for the training data and the fake training data, which we'll both use.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\ntrain <- data.table::fread(\"../../../PreFer_data/PreFer_train_data.csv\", \n                           keepLeadingZeros = TRUE, # if FALSE adds zeroes to some dates\n                           data.table = FALSE) # returns a data.frame object rather than data.table \noutcome <- data.table::fread(\"../../../PreFer_data/PreFer_train_outcome.csv\", \n                           keepLeadingZeros = TRUE, data.table = FALSE)\nfake <- data.table::fread(\"../../../PreFer_data/PreFer_fake_data.csv\", \n                          keepLeadingZeros = TRUE, data.table = FALSE)\n\nclean <- clean_df(train)\nstr(clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n num [1:2939, 1:12] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:2939] \"2\" \"3\" \"5\" \"9\" ...\n  ..$ : chr [1:12] \"(Intercept)\" \"nomem_encr\" \"birthyear_bg\" \"gender_bg2\" ...\n - attr(*, \"assign\")= int [1:12] 0 1 2 3 4 4 4 4 4 4 ...\n - attr(*, \"contrasts\")=List of 2\n  ..$ gender_bg  : chr \"contr.treatment\"\n  ..$ oplmet_2020: chr \"contr.treatment\"\n```\n:::\n:::\n\n\nA matrix with 2939 cases and 12 variables. \n\n# Using training.R\nWe'll use this dataset (matrix) for training, using the `train_save_model` function in `training.R`. We want to do a penalized regression. We'll first do a 10-fold cross-validation, determine the optimal penalty (lambda), and run another penalized regression using this lambda [nested cross-validation may be more appropriate here, but we'll go with it]. \n\n*training.R:*\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_save_model <- function(cleaned_df, outcome_df) {\n  set.seed(1) # useful here because penalized regression not deterministic\n  \n  # Combine cleaned_df and outcome_df to match on ID\n  model_df <- merge(cleaned_df, outcome_df, by = \"nomem_encr\")\n  \n  # glmnet requires matrix, and also features (X) separately from outcome (y)\n  model_df <- as.matrix(model_df) # merged filed into matrix\n  \n  # features without outcome and identifier\n  X <- model_df[ , !(colnames(model_df) %in% c(\"nomem_encr\", \"new_child\"))]\n  y <- model_df[ , colnames(model_df) == \"new_child\"] # outcome only\n  \n  ## LASSO regression ##\n  # hyperparameter tuning: 10 fold cross-validation to retrieve optimal lambda\n  CV <- cv.glmnet(x = X,  y = y, \n                  family = \"binomial\", nfolds = 10, standardize = FALSE)\n  optimal_lambda <- CV$lambda.min\n  \n  # Run model with optimal lambda\n  model <- glmnet(x = X, y = y, \n                  family = \"binomial\", \n                  lambda = optimal_lambda, standardize = FALSE )\n  \n  # Save the model\n  saveRDS(model, \"model.rds\")\n}\n```\n:::\n\n\nWill it work?!\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_save_model(clean, outcome)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in if (!all(o)) {: missing value where TRUE/FALSE needed\n```\n:::\n:::\n\n\nSome error about missing values. This is actually about missing values in the outcome variable, which glmnet does not except. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(outcome$new_child, useNA = \"always\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   0    1 <NA> \n 775  212 5431 \n```\n:::\n:::\n\n\n\n# Back to submission.R \n\nAnnoyingly, there are some missing values in the outcome values, and this means that we want to exclude all cases with missing outcome values (or impute the outcomes). We have created the variable `outcome_available` for this reason, which has a `1` if the outcome is available. Let's update our `clean_df` function.\n\n\n*Updated first part of submission.R:*\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_df <- function(df, background_df = NULL){\n  \n  # glmnet requires that outcome is available for all cases\n  df <- df |> filter(outcome_available == 1)\n  \n  ## Selecting variables, we don't need outcome_available!\n  keepcols = c('nomem_encr', # ID variable required for predictions,\n               'birthyear_bg', # birthyear of respondents\n               'gender_bg', # gender of respondents, factor\n               'oplmet_2020') # highest educational level in 2020\n  \n  ## Keeping data with variables selected\n  df <- df |> select(all_of(keepcols))\n  \n  df <- df |>\n    # standardise continuous variable, create factor for categorical variables\n    # needed for glmnet\n    mutate(\n      birthyear_bg = as.numeric(scale(birthyear_bg)), # z-scores, as.numeric to remove attributes\n      gender_bg = factor(gender_bg),\n      oplmet_2020 = factor(oplmet_2020)\n    )\n  \n  # turn factors into dummy variables, required for glmnet\n  df <- model.matrix(~ ., df)\n  \n  return(df)\n}\n```\n:::\n\n\nLet's try again with our updated `clean_df`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean <- clean_df(train)\ntrain_save_model(clean, outcome)\n```\n:::\n\n\nScore! The function worked, and a `model.rds` was created. \n\n# Working on submission.R: predict_outcomes\n\nOnly one more step: trying to see if we can make predictions via `predict_outcomes` in `submission.R`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_outcomes <- function(df, background_df = NULL, model_path = \"./model.rds\"){\n  \n  if( !(\"nomem_encr\" %in% colnames(df)) ) {\n    warning(\"The identifier variable 'nomem_encr' should be in the dataset\")\n  }\n  \n  # Load the model\n  model <- readRDS(model_path)\n  \n  # Preprocess the fake / holdout data\n  df <- clean_df(df) # is matrix\n  \n  # Exclude id because not used in model\n  X_pred <- df[ , !(colnames(df) %in% c(\"nomem_encr\"))]\n  \n  # Generate predictions from model\n  predictions <- predict(model, \n                         X_pred, \n                         type = \"response\") \n  predictions <- ifelse(predictions > 0.5, 1, 0)  \n  \n  # Output file should be data.frame with two columns, nomem_encr and predictions\n  df_predict <- data.frame(\"nomem_encr\" = df[ , colnames(df) == \"nomem_encr\"], \n                           \"prediction\" = predictions)\n  # Force columnnames (overrides names that may be given by `predict`)\n  names(df_predict) <- c(\"nomem_encr\", \"prediction\") \n  \n  # Return only dataset with predictions and identifier\n  return( df_predict )\n  \n}\n```\n:::\n\n\nLet's check. It works on the training data itself! \n\n::: {.cell}\n\n```{.r .cell-code}\npredict_outcomes(train) |> head() # only first couple of rows\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  nomem_encr prediction\n1     715619          0\n2     716711          0\n3     717188          0\n4     712090          0\n5     709537          0\n6     701934          0\n```\n:::\n:::\n\n\nLet's check on fake data:\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_outcomes(fake) |> head() # only first couple of rows\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  nomem_encr prediction\n1     700001          0\n2     700002          0\n3     700003          0\n4     700004          0\n5     700005          0\n6     700006          0\n```\n:::\n:::\n\nSuccess. \n\n# Adding packages to packages.R\nWe have used the packages `dplyr`, `tidyr`, and `glmnet`, which means you will also put these packages into `packages.R`. \n\n# settings.json\nMake sure you have written `{\"dockerfile\": \"r.Dockerfile\"}` in `settings.json`\n\n# Testing everything\nEven though we have now tested everything manually, it's still good to do a check via the terminal with `Rscript run.R PreFer_fake_data.csv PreFer_fake_background_data.csv`.\n\n[Here](https://github.com/gertstulp/fertility-prediction-challenge/tree/usebackground){target=\"_blank\"} you can see it in action and that it passes the check.\n\n\n\n<font size=\"-1\">Photo by <a href=\"https://unsplash.com/@ffstop?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Fotis Fotopoulos</a> on <a href=\"https://unsplash.com/photos/black-computer-keyboard-DuHKoV44prg?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a></font> | <font size=\"-1\">Photo by <a href=\"https://unsplash.com/@kelli_mcclintock?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Kelli McClintock</a> on <a href=\"https://unsplash.com/photos/white-box-on-white-table-GopRYASfsOc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a></font>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}